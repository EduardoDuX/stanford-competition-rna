{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criacao da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monta_base(sequencias, labels, define_encoder = False):\n",
    "    base_seqs = pd.read_csv(sequencias)\n",
    "    base_labels = pd.read_csv(labels)\n",
    "\n",
    "    base_seqs[\"resname\"] = base_seqs[\"sequence\"].apply(lambda x: list(x))\n",
    "    base_seqs = base_seqs[[\"target_id\", \"sequence\", \"resname\"]].explode(\"resname\", ignore_index=True)\n",
    "    base_seqs[\"resid\"] = base_seqs.groupby(\"target_id\").cumcount() + 1\n",
    "    base_seqs[\"target_num\"] = base_seqs[\"target_id\"] + \"_\" + base_seqs[\"resid\"].astype(str)\n",
    "    \n",
    "    base_set = pd.merge(base_seqs[[\"target_num\", \"sequence\", 'target_id']], base_labels, left_on=\"target_num\", right_on=\"ID\").drop(\"target_num\", axis=1)\n",
    "\n",
    "\n",
    "    base_set = base_set.dropna(how='any', axis=0).reset_index().drop('index', axis=1)\n",
    "\n",
    "    base_set['first'] = (base_set['ID'] == base_set['ID'].iloc[0]).astype(int)\n",
    "    base_set['last'] = (base_set['ID'] == base_set['ID'].iloc[-1]).astype(int)\n",
    "    base_set['lead1'] = base_set['resname'].shift(-1)\n",
    "    base_set['lead2'] = base_set['resname'].shift(-2)\n",
    "    base_set['lead3'] = base_set['resname'].shift(-3)\n",
    "    base_set['lag1'] = base_set['resname'].shift(1)\n",
    "    base_set['lag2'] = base_set['resname'].shift(2)\n",
    "    base_set['lag3'] = base_set['resname'].shift(3)\n",
    "\n",
    "    colunas_one_hot = ['resname', 'lead1', 'lead2', 'lead3', 'lag1', 'lag2', 'lag3']\n",
    "    df_one_hot = base_set[colunas_one_hot]\n",
    "    df_one_hot['ID'] = '0'\n",
    "    colunas_one_hot.append('ID')\n",
    "\n",
    "    if define_encoder:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        codificados = enc.fit(df_one_hot)\n",
    "        joblib.dump(enc, \"onehot_encoder.pkl\")\n",
    "\n",
    "        \n",
    "    enc = joblib.load(\"onehot_encoder.pkl\")\n",
    "    codificados = enc.transform(df_one_hot).toarray()\n",
    "\n",
    "    renames = []\n",
    "    for coluna, cats in zip(colunas_one_hot, enc.categories_):\n",
    "        # print(coluna, cat)\n",
    "        for cat in cats:\n",
    "            if cat is None:\n",
    "                cat = 'None'\n",
    "            renames.append(coluna + '_' + cat)\n",
    "\n",
    "    codificados = pd.DataFrame(codificados, columns=renames).iloc[:, :-1]\n",
    "\n",
    "    base_set = pd.concat([base_set, codificados], axis=1)\n",
    "\n",
    "    cols = renames[:-1]\n",
    "    cols.extend(['first', 'last'])\n",
    "\n",
    "    X = base_set[cols].fillna(99)\n",
    "    y = base_set[['x_1', 'y_1', 'z_1']]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\AppData\\Local\\Temp\\ipykernel_32028\\1918933705.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_one_hot['ID'] = '0'\n",
      "C:\\Users\\pedro\\AppData\\Local\\Temp\\ipykernel_32028\\1918933705.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_one_hot['ID'] = '0'\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = monta_base(\"train_sequences.csv\", \"train_labels.csv\", False)\n",
    "X_validation, y_validation = monta_base(\"validation_sequences.csv\", \"validation_labels.csv\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resname_-</th>\n",
       "      <th>resname_A</th>\n",
       "      <th>resname_C</th>\n",
       "      <th>resname_G</th>\n",
       "      <th>resname_U</th>\n",
       "      <th>lead1_-</th>\n",
       "      <th>lead1_A</th>\n",
       "      <th>lead1_C</th>\n",
       "      <th>lead1_G</th>\n",
       "      <th>lead1_U</th>\n",
       "      <th>...</th>\n",
       "      <th>lag2_U</th>\n",
       "      <th>lag2_None</th>\n",
       "      <th>lag3_-</th>\n",
       "      <th>lag3_A</th>\n",
       "      <th>lag3_C</th>\n",
       "      <th>lag3_G</th>\n",
       "      <th>lag3_U</th>\n",
       "      <th>lag3_None</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2515 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      resname_-  resname_A  resname_C  resname_G  resname_U  lead1_-  lead1_A  \\\n",
       "0           0.0        0.0        0.0        1.0        0.0      0.0      0.0   \n",
       "1           0.0        0.0        0.0        1.0        0.0      0.0      0.0   \n",
       "2           0.0        0.0        0.0        1.0        0.0      0.0      0.0   \n",
       "3           0.0        0.0        0.0        1.0        0.0      0.0      0.0   \n",
       "4           0.0        0.0        0.0        1.0        0.0      0.0      0.0   \n",
       "...         ...        ...        ...        ...        ...      ...      ...   \n",
       "2510        0.0        0.0        0.0        0.0        1.0      0.0      0.0   \n",
       "2511        0.0        0.0        0.0        0.0        1.0      0.0      0.0   \n",
       "2512        0.0        0.0        0.0        0.0        1.0      0.0      0.0   \n",
       "2513        0.0        0.0        0.0        0.0        1.0      0.0      0.0   \n",
       "2514        0.0        0.0        0.0        0.0        1.0      0.0      0.0   \n",
       "\n",
       "      lead1_C  lead1_G  lead1_U  ...  lag2_U  lag2_None  lag3_-  lag3_A  \\\n",
       "0         0.0      1.0      0.0  ...     0.0        1.0     0.0     0.0   \n",
       "1         0.0      1.0      0.0  ...     0.0        1.0     0.0     0.0   \n",
       "2         0.0      1.0      0.0  ...     0.0        0.0     0.0     0.0   \n",
       "3         0.0      1.0      0.0  ...     0.0        0.0     0.0     0.0   \n",
       "4         1.0      0.0      0.0  ...     0.0        0.0     0.0     0.0   \n",
       "...       ...      ...      ...  ...     ...        ...     ...     ...   \n",
       "2510      0.0      0.0      1.0  ...     0.0        0.0     0.0     0.0   \n",
       "2511      0.0      0.0      1.0  ...     0.0        0.0     0.0     0.0   \n",
       "2512      0.0      0.0      1.0  ...     1.0        0.0     0.0     0.0   \n",
       "2513      0.0      0.0      1.0  ...     1.0        0.0     0.0     0.0   \n",
       "2514      0.0      0.0      0.0  ...     1.0        0.0     0.0     0.0   \n",
       "\n",
       "      lag3_C  lag3_G  lag3_U  lag3_None  first  last  \n",
       "0        0.0     0.0     0.0        1.0      1     0  \n",
       "1        0.0     0.0     0.0        1.0      0     0  \n",
       "2        0.0     0.0     0.0        1.0      0     0  \n",
       "3        0.0     1.0     0.0        0.0      0     0  \n",
       "4        0.0     1.0     0.0        0.0      0     0  \n",
       "...      ...     ...     ...        ...    ...   ...  \n",
       "2510     1.0     0.0     0.0        0.0      0     0  \n",
       "2511     1.0     0.0     0.0        0.0      0     0  \n",
       "2512     1.0     0.0     0.0        0.0      0     0  \n",
       "2513     0.0     0.0     1.0        0.0      0     0  \n",
       "2514     0.0     0.0     1.0        0.0      0     1  \n",
       "\n",
       "[2515 rows x 43 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resname_-</th>\n",
       "      <th>resname_A</th>\n",
       "      <th>resname_C</th>\n",
       "      <th>resname_G</th>\n",
       "      <th>resname_U</th>\n",
       "      <th>lead1_-</th>\n",
       "      <th>lead1_A</th>\n",
       "      <th>lead1_C</th>\n",
       "      <th>lead1_G</th>\n",
       "      <th>lead1_U</th>\n",
       "      <th>...</th>\n",
       "      <th>lag2_U</th>\n",
       "      <th>lag2_None</th>\n",
       "      <th>lag3_-</th>\n",
       "      <th>lag3_A</th>\n",
       "      <th>lag3_C</th>\n",
       "      <th>lag3_G</th>\n",
       "      <th>lag3_U</th>\n",
       "      <th>lag3_None</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130945</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130946</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130947</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130948</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130949</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130950 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        resname_-  resname_A  resname_C  resname_G  resname_U  lead1_-  \\\n",
       "0             0.0        0.0        0.0        1.0        0.0      0.0   \n",
       "1             0.0        0.0        0.0        1.0        0.0      0.0   \n",
       "2             0.0        0.0        0.0        1.0        0.0      0.0   \n",
       "3             0.0        0.0        0.0        0.0        1.0      0.0   \n",
       "4             0.0        0.0        0.0        1.0        0.0      0.0   \n",
       "...           ...        ...        ...        ...        ...      ...   \n",
       "130945        0.0        0.0        0.0        0.0        1.0      0.0   \n",
       "130946        0.0        1.0        0.0        0.0        0.0      0.0   \n",
       "130947        0.0        0.0        1.0        0.0        0.0      0.0   \n",
       "130948        0.0        0.0        1.0        0.0        0.0      0.0   \n",
       "130949        0.0        1.0        0.0        0.0        0.0      0.0   \n",
       "\n",
       "        lead1_A  lead1_C  lead1_G  lead1_U  ...  lag2_U  lag2_None  lag3_-  \\\n",
       "0           0.0      0.0      1.0      0.0  ...     0.0        1.0     0.0   \n",
       "1           0.0      0.0      1.0      0.0  ...     0.0        1.0     0.0   \n",
       "2           0.0      0.0      0.0      1.0  ...     0.0        0.0     0.0   \n",
       "3           0.0      0.0      1.0      0.0  ...     0.0        0.0     0.0   \n",
       "4           0.0      1.0      0.0      0.0  ...     0.0        0.0     0.0   \n",
       "...         ...      ...      ...      ...  ...     ...        ...     ...   \n",
       "130945      1.0      0.0      0.0      0.0  ...     1.0        0.0     0.0   \n",
       "130946      0.0      1.0      0.0      0.0  ...     1.0        0.0     0.0   \n",
       "130947      0.0      1.0      0.0      0.0  ...     1.0        0.0     0.0   \n",
       "130948      1.0      0.0      0.0      0.0  ...     0.0        0.0     0.0   \n",
       "130949      0.0      0.0      0.0      0.0  ...     0.0        0.0     0.0   \n",
       "\n",
       "        lag3_A  lag3_C  lag3_G  lag3_U  lag3_None  first  last  \n",
       "0          0.0     0.0     0.0     0.0        1.0      1     0  \n",
       "1          0.0     0.0     0.0     0.0        1.0      0     0  \n",
       "2          0.0     0.0     0.0     0.0        1.0      0     0  \n",
       "3          0.0     0.0     1.0     0.0        0.0      0     0  \n",
       "4          0.0     0.0     1.0     0.0        0.0      0     0  \n",
       "...        ...     ...     ...     ...        ...    ...   ...  \n",
       "130945     0.0     0.0     0.0     1.0        0.0      0     0  \n",
       "130946     0.0     0.0     0.0     1.0        0.0      0     0  \n",
       "130947     0.0     0.0     0.0     1.0        0.0      0     0  \n",
       "130948     0.0     0.0     0.0     1.0        0.0      0     0  \n",
       "130949     1.0     0.0     0.0     0.0        0.0      0     1  \n",
       "\n",
       "[130950 rows x 43 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 467.36it/s, loss=2.26e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 22575.8171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 959.81it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 1/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 471.94it/s, loss=1.96e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 19570.5451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 918.54it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 2/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 478.18it/s, loss=1.78e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 17777.1514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1202.35it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 3/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 484.56it/s, loss=1.69e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16864.8530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1258.82it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 4/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 509.19it/s, loss=1.65e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16524.2794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 939.82it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 5/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 496.04it/s, loss=1.64e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16429.7828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 967.75it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214546246946314386611837599744.0000\n",
      "Epoch 6/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 501.31it/s, loss=1.64e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16408.0338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 954.83it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214546246946314386611837599744.0000\n",
      "Epoch 7/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 485.01it/s, loss=1.64e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16402.6683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 893.93it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 8/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 489.26it/s, loss=1.64e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16401.2518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 985.49it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 9/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 494.28it/s, loss=1.64e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16399.1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 929.45it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 10/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 495.04it/s, loss=1.64e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16392.2295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 943.70it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 11/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 498.68it/s, loss=1.64e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16375.4250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 940.47it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 12/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 495.45it/s, loss=1.64e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16360.7553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 907.04it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214546246946314386611837599744.0000\n",
      "Epoch 13/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 489.70it/s, loss=1.64e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16353.5701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 925.24it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 14/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 498.31it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16346.7278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1158.21it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 15/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 497.71it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16338.6834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1072.29it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214471429097938340743825326080.0000\n",
      "Epoch 16/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 508.22it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16328.9331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 951.44it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214471429097938340743825326080.0000\n",
      "Epoch 17/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 506.75it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16319.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1128.22it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 18/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 480.30it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16310.4702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1110.04it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 19/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 503.71it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16303.6282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 970.37it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 20/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 504.74it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16297.3601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 948.92it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 21/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 501.19it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16292.5019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1131.64it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 22/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 496.94it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16287.6880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1050.23it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214471429097938340743825326080.0000\n",
      "Epoch 23/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 467.59it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16283.1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 990.24it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 24/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 497.20it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16279.1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 995.77it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 25/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:07<00:00, 524.05it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16275.4310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1229.04it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 26/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 490.08it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16271.9522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 990.09it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 27/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 496.01it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16268.5395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 951.38it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 28/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 498.04it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16265.4734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 900.38it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 29/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 489.85it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16262.6230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 900.48it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 30/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 502.55it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16259.7698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 948.93it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 31/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 494.52it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16257.2120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1140.08it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 00032: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 32/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 492.95it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16255.9718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 968.80it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 33/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 501.57it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16255.5846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 999.45it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 34/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 491.29it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16255.2041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1097.98it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 35/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 500.52it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16254.8713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 950.37it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 36/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 488.48it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16254.5397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 871.82it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 37/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 482.48it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16254.2719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1126.04it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 38/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 486.82it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16253.9865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1030.88it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 39/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 478.67it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16253.7497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 830.58it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 40/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 494.60it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16253.5173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1005.74it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214546246946314386611837599744.0000\n",
      "Epoch 41/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 485.05it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16253.2690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1074.08it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 42/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 501.10it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16253.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1137.66it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 43/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 495.98it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16252.8529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 975.44it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214471429097938340743825326080.0000\n",
      "Epoch 44/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 492.89it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16252.6432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1205.33it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 45/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 493.79it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16252.3927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 928.53it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 46/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 489.63it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16252.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 957.93it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 47/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 501.16it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16251.9165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 944.57it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214546246946314386611837599744.0000\n",
      "Epoch 48/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 501.35it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16251.6675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 967.12it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 49/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 478.81it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16251.4679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 908.18it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214471429097938340743825326080.0000\n",
      "Epoch 50/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:09<00:00, 450.32it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16251.2617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 984.40it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 51/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 477.42it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16251.1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1135.51it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 52/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 482.78it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16250.9139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 923.89it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 53/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 479.24it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16250.5918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1103.67it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 54/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 482.89it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16250.4666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1191.69it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 55/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 492.49it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16250.2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1009.10it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 56/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 499.96it/s, loss=1.63e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16250.0233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 974.09it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 57/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 494.37it/s, loss=1.62e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16249.7692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 872.83it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 58/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 495.68it/s, loss=1.62e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16249.5873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1025.47it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214546246946314386611837599744.0000\n",
      "Epoch 59/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 501.24it/s, loss=1.62e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16249.2840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 987.47it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 60/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 490.84it/s, loss=1.62e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16249.1772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1021.68it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 61/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 496.95it/s, loss=1.62e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16248.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1197.61it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 62/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 487.63it/s, loss=1.62e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16248.7610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1016.24it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 00063: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 63/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 479.14it/s, loss=1.62e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16248.6109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 1176.60it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 64/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:07<00:00, 513.42it/s, loss=1.62e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16248.5919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 954.70it/s, loss=5.96e+33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Epoch 65/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 4093/4093 [00:08<00:00, 493.92it/s, loss=1.62e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16248.5749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 79/79 [00:00<00:00, 861.30it/s, loss=5.96e+33]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5964214483242442418769038774632448.0000\n",
      "Early stopping! No improvement in validation loss for 50 epochs.\n",
      "Best Loss: 5.964214471429098e+33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Supondo que df seja um DataFrame Pandas já carregado\n",
    "\n",
    "# Convertendo para tensores\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)  # Agora float, pois são valores binários\n",
    "Y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "\n",
    "X_validation_tensor = torch.tensor(X_validation.values, dtype=torch.float32).to(device)  # Agora float, pois são valores binários\n",
    "Y_validation_tensor = torch.tensor(y_validation.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Criando um Dataset personalizado\n",
    "class RNA3DDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "# Criando instância do Dataset\n",
    "dataset_train = RNA3DDataset(X_train_tensor, Y_train_tensor)\n",
    "dataset_val = RNA3DDataset(X_validation_tensor, Y_validation_tensor)\n",
    "\n",
    "# Criando DataLoader para carregar os dados em batches\n",
    "BATCH_SIZE = 32\n",
    "# train_loader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_loader = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# Definições\n",
    "INPUT_DIM = X_train_tensor.shape[1]  # 43 valores binários\n",
    "LSTM_UNITS = 64\n",
    "OUTPUT_DIM = 3  # Coordenadas X, Y, Z por nucleotídeo\n",
    "\n",
    "# Criando o modelo\n",
    "class RNA3DModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNA3DModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(INPUT_DIM, LSTM_UNITS, batch_first=True)\n",
    "        self.fc = nn.Linear(LSTM_UNITS, OUTPUT_DIM)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x, _ = self.lstm(x)  # Pegamos todas as saídas da LSTM\n",
    "        x = self.fc(x[:, -1, :])  # Pegamos apenas a última saída da sequência\n",
    "        return x\n",
    "    \n",
    "# Instanciando o modelo\n",
    "model = RNA3DModel().to(device)\n",
    "\n",
    "# Função de perda e otimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Função de treinamento\n",
    "def train_model(model, criterion, optimizer, dataloaders, dataset_sizes, scheduler=None, num_epochs=25, patience=15):\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            is_train = phase == 'train'\n",
    "            model.train() if is_train else model.eval()\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            progress_bar = tqdm(dataloaders[phase], desc=f'{phase.capitalize()}')\n",
    "            \n",
    "            for batch_X, batch_Y in progress_bar:\n",
    "                batch_X = batch_X.to(device, dtype=torch.float32)\n",
    "                batch_Y = batch_Y.to(device, dtype=torch.float32)\n",
    "                with torch.set_grad_enabled(is_train):\n",
    "                    output = model(batch_X)\n",
    "                    loss = criterion(output, batch_Y)\n",
    "                    \n",
    "                    if is_train:\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                running_loss += loss.item() * batch_X.size(0)\n",
    "                current_loss = running_loss / dataset_sizes[phase]\n",
    "                progress_bar.set_postfix({'loss': current_loss})\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f}')\n",
    "            \n",
    "            if phase == 'val' and scheduler:\n",
    "                scheduler.step(epoch_loss)\n",
    "            \n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    epochs_no_improve = 0\n",
    "                    torch.save(model.state_dict(), 'best_model.pt')\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'Early stopping! No improvement in validation loss for {patience} epochs.')\n",
    "            print(f'Best Loss: {best_loss}')\n",
    "            break\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Criando DataLoaders e scheduler\n",
    "batch_size = 32\n",
    "fine_dataloaders = {\n",
    "    'train': DataLoader(dataset_train, batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(dataset_val, batch_size=batch_size, shuffle=True),\n",
    "}\n",
    "\n",
    "fine_dataset_sizes = {\n",
    "    'train': len(dataset_train),\n",
    "    'val': len(dataset_val)\n",
    "}\n",
    "\n",
    "l2_lambda = 0.3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)#, weight_decay=l2_lambda)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=30, verbose=True)\n",
    "\n",
    "# Treinando o modelo\n",
    "model = train_model(model, criterion, optimizer, fine_dataloaders, fine_dataset_sizes, scheduler=scheduler, num_epochs=500, patience=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([16, 36])\n",
      "torch.Size([16, 3])\n",
      "torch.Size([3, 36])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "for batch_X, batch_Y in DataLoader(dataset_val, batch_size=batch_size, shuffle=True):\n",
    "    print(batch_X.shape)  # Deve ser (batch_size, input_dim)\n",
    "    print(batch_Y.shape)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
